# 2.1 Random Variables
Formally, a *random variable* is a *function* from the sample space $\Omega$ to $\mathbb{R}$. Here is a concrete example:

### Example 2.1 (Sum of Two Dice)
Suppose we toss two fair dice and note their sum. If we throw the dice one by one and observe each throw, the sample space is $\Omega = \{ (1,1),\dots,(6,6) \}$. The function, $X$, defined by $X(i,j)=i+j$, is a random variable, which maps the outcome $(i,j)$ to the sum $i+j$. Note that all the outcomes in the "encircled" set are mapped to 8. This is the set of all outcomes whose sum is 8. A natural notation for this set is to write $\{ X=8 \}$ Since this set has 5 outcomes, and all outcomes in $\Omega$ are equally likely, we have
$$
\mathbb{P}(\{ X=8 \})=\frac{5}{36}
$$
This notation is very suggestive and convenient. From a non-mathematical viewpoint we can interpret $X$ as a "random" variable. That is a variable that can take on several values, with certain probabilities. In particular it is not difficult to check that
$$
\mathbb{P}(\{ X=x \}) = \frac{6-|7-x|}{36}, \quad x=2,\dots, 12.
$$
![[Pasted image 20250515140008.png]]

Although random variables are, mathematically speaking, *functions*, it is often convenient to view random variables as observations of a random experiment that has not yet been carried out. In other words, a random variable is considered as a measurement that becomes available once we carry out the random experiment, e.g. *tomorrow*. However, all the *thinking* about the experime